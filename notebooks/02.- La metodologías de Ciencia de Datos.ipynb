{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM\n",
    "\n",
    "El crecimiento del interés de la industria en las metodologías de inteligencia artificial ha venido acompañado de una formalización del proceso de desarrollo de soluciones. Este fenómeno es particularmente notable en el área de análisis inteligente de dato, destacándose las siguientes metodologías:\n",
    "* [KDD](https://decisionstats.com/2009/08/13/interview-gregory-piatetsky-kdnuggets-com/) (Knowledge Discovery in Databases). Es una metodología general, formalizada principal- mente por Usama Fayyad (investigador en Microsoft Research) y sus colaboradores, para describir el proceso de generación de conocimiento a partir de datos.\n",
    "* [CRISP-DM](https://www.the-modeling-agency.com/crisp-dm.pdf) (Cross-Industry Standard Process for Data Mining). Esta metodología fue propuesta por un un consosrcio formado por las empresas Daimler Chrysler AG, SPSS Inc. y NCR Systems Engineering Copenhagen con el apoyo del banco OHRA Verzekeringen en Bank Groep B.V. A diferencia de KDD, CRISP-DM presta especial atención a la comprensión del negocio como directriz del proceso de minería de datos.\n",
    "* [TDSP](https://azure.microsoft.com/en-gb/documentation/learning-paths/data-science-process/) (Team Data Science Process). Es una metodología para el desarrollo de proyectos de ciencias de datos propuesta por Microsoft en 2016. TDSP presenta gran semejanza con CRISP- DM pero, a diferencia de su antecesor, enfatiza y especifica diversos aspectos de implementación, incluyendo estructuras de archivos para los proyectos y organización del equipo de ciencia de datos.\n",
    "* [ASUM-DM](ftp://ftp.software.ibm.com/software/data/sw-library/services/ASUM.pdf) (Analytics Solutions Unified Method for Data Mining) es una refinamiento y ex- tensión de CRISP-DM propuesto por IBM en 2015 en torno a su herramienta IBM Analytics.\n",
    "\n",
    "A pesar de frecuentes críticas por sus limitaciones, particularmente en lo referente a la fase de toma de decisiones, y aún cuando no ha sido actualizada, CRISP-DM sigue siendo la metodología más reconocida, particularmente en la industria, para el manejo de proyectos de ciencia de datos.\n",
    "\n",
    "**CRISP-DM** es un marco de referencia que permite planificar el desarrollo de un proyecto de minería de datos (y asociados) a partir de 6 fases: 1) *Comprensión del negocio*, 2) *Comprensión de los datos*, 3) *Preparación de los datos*, 4) *Modelado*, 5) *Evaluación* y 6) *Despliegue* (implementación/puesta en marcha).\n",
    "\n",
    "[![](../images/crisp_dm_diagram.png)](https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome) <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Comprensión del negocio**<br>\n",
    "La fase inicial de un proyecto de minería de datos (y similares) se enfoca en entender los objetivos y requerimientos del proyecto, desde la perspectiva del *negocio*: a) identificar las características del problema que se quiere resolver, b) identificar cuáles son las necesidades prioritarias que el *cliente* quiere satisfacer y c) cuáles son los costos que el cliente está dispuesto a *pagar*. El resultado de esta fase debe ser la definición de un problema en términos técnicos (un problema de minería de datos, por ejemplo) y un plan preliminar de como alcanzar los objetivos.<br><br>Las actividades en esta fase con sus respectivos resultados esperados son:\n",
    "    * *Establecimiento de los objetivos del negocio*. El objetivo de este conjunto de actividades es conocer las características del cliente: ¿Cuáles son sus antecedentes? ¿Cuáles son sus objetivos de negocio? ¿Cuáles son los criterios de éxito del negocio?\n",
    "    * *Evaluación de la situación*. Con estas actividades se busca conocer la situación de la empresa para determinar su capacidad para explotar los datos con que cuenta. Entre las preguntas que hay que responder se encuentran las siguientes: ¿Cuáles son los términos más importantes para describir el negocio? ¿Con qué recursos humanos y materiales cuenta la empresa para completar el proyecto? ¿Qué tipos de datos están disponibles para el proyecto? ¿Cuáles son los principales factores de riesgo? ¿Cuáles son los planes de contingencia para cada factor de riesgo? ¿Cuáles son los potenciales costos y beneficios del proyecto?\n",
    "    * *Establecimiento de los objetivos de la minería de datos*. Establecimiento de los objetivos de la minería de datos. Aquí se busca determinar los objetivos del proyecto de minería de datos y los criterios que permiten evaluar el éxito del proyecto: ¿Qué se espera obtener con el proyecto?, ¿una nueva herramienta o servicio?, ¿información para planificación estratégica? ¿Cuáles son los KPIs?\n",
    "    * *Generación del plan del proyecto*. La fase de comprensión del negocio debe concretarse en una determinación de intervención (hasta este punto, ¿se considera viable la realización del proyecto?) y en caso de ser positiva, en un plan de como realizar las siguientes fases de intervención (recursos a utilizar, compromisos, indicadores de avances, etc.).\n",
    "\n",
    "![](../images/crisp_dm_flow01.png)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Comprensión de los datos**<br>\n",
    "La comprensión de los datos se refiere a familiarizarse con las características de los datos disponibles para el proyecto y de los requerimientos adicionales de datos. Es una actividad fundamental para el desarrollo del proyecto dado que ésta es la base de todas las actividades que se realizarán a continuación. Es por ello que, en ocasiones, será necesario regresar a analizar el negocio con el fin de comprender mejor los datos.<br><br>Las actividades en esta fase, con sus respectivos resultados esperados son:\n",
    "    * *Recolección inicial de datos*. En este primer paso, se toman muestras de los datos disponibles y se identifica el alcance, así como posibles dificultades para su recolección y uso. Se distinguen los datos propios de la empresa de otros conjuntos de datos complementarios adquiridos y se identifican las fuentes adicionales de datos.\n",
    "    * *Descripción de los datos*. A continuación, se identifican las características generales de los datos, como son el número de variables disponibles, la cantidad de registros, la frecuencia de generación de cada variable, su identificación, el significado de cada campo y el formato inicial. El resultado más importante de este análisis preliminar es una determinación de si los datos disponibles son suficientes para alcanzar los objetivos de la minería de datos.\n",
    "    * *Exploración de los datos*. El objetivo de esta actividad es identificar la\n",
    "distribución general de los datos a través de pruebas estadísticas básicas y establecer hipótesis preliminares. Este análisis permite identificar la complejidad del problema y realizar una selección preliminar de técnicas a utilizar.\n",
    "    * *Verificación de la calidad de los datos*. En este paso se verifica la completitud  de los datos. Se buscan los porcentajes de datos incompletos, valores fuera de rango o no típicos y variables equivalentes. Se definen estrategias generales para resolver los problemas identificados.\n",
    "\n",
    "![](../images/crisp_dm_flow02.png)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Preparación de los datos**<br>\n",
    "La fase de preparación de los datos incluye todas las actividades necesarias para generar el conjunto de datos final que se utilizará para alimentar los modelos, partiendo de los datos originales. Está ampliamente reconocido que esta suele ser la fase que consume más tiempo en un proyecto de ciencia de los datos.<br><br>En esta fase se realizan las siguientes actividades:\n",
    "    * *Selección de los datos*. Aquí se busca escoger una porción del volumen total de datos preseleccionados que parezca representativa del problema de minería de datos. Por una parte, se realiza una selección de registros suficientemente amplia para cubrir todo el universo de objetos a analizar y, por otra parte, se seleccionan las  características (variables) que mejor describen los diferentes objetos, tratando de tener la representación más rica posible y evitar, al mismo tiempo, variables que sean básicamente equivalentes. Es importante justificar y documentar las razones por las que diferentes subconjuntos de datos se van a incluir o excluir.\n",
    "    * *Limpieza de los datos*. Esta actividad, que es la que más tiempo y recursos consume, tiene el objeto de subsanar las deficiencias de los datos identificadas en la fase previa. Entre las principales tareas a realizar sobresale el tratamiento a datos con valores faltantes y el manejo de datos atípicos y/o inconsistentes.\n",
    "    * *Estructuración de los datos*. Esta actividad consiste en generar la estructura de los registros que se emplearán en el análisis, principalmente mediante la generación de nuevas variables que resulten más descriptivas de los datos y que ayuden a reducir la complejidad del espacio de representación.\n",
    "    * *Integración de los datos*. La integración de datos consiste en unir datos de diferentes fuentes en un sólo conjunto de datos. Puede tratarse de crear una tabla unificada a partir de diferentes tablas o de generar registros o columnas nuevas a partir de la agregación de datos de diferentes fuentes.\n",
    "    * *Formateo de los datos*. Esta actividad tiene el objeto de poner los datos en la forma en que serán procesados, típicamente mediante transformaciones que no alteran su significado. Entre las tareas más tareas más comunes de formateo de datos se encuentran el cambio de escala, la eliminación de caracteres especiales y el reordenamiento de columnas y renglones en datos tabulares. \n",
    "\n",
    "![](../images/crisp_dm_flow03.png)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Modelado**<br>\n",
    "En esta fase se eligen y se prueban diversas técnicas de modelado, afinando sus parámetros para ajustarse a la dinámica representada por los datos. En el proceso, suele ocurrir que una técnica requiera datos no contemplados en las fases previas y sea necesario dar marcha atrás para rectificar la construcción del conjunto de datos. La elección de las técnicas a utilizar se realiza utilizando criterios técnicos (como la pertinencia de la técnica para el problema específico) y prácticos (como la disponibilidad de datos adecuados, el tiempo disponible para obtener un modelo o el conocimiento de la técnica por parte del equipo de desarrollo). <br><br>Las actividades en esta fase, con sus respectivos resultados esperados son:\n",
    "    * *Selección de las técnicas de modelado*. En este paso, se eligen las técnicas de modelado que se emplearán. La selección depende de una serie de factores relativos al proyecto, entre los que destacan el grado de estructuración del problema y de los datos (¿existen modelos formales del sistema?, ¿Existen relaciones bien identificadas entre variables?, ¿se dispone de conocimiento experto?, ¿existen suficientes datos de observación?, ¿de qué tipo son los datos existentes?), los objetivos de la minería de datos, el dominio de técnicas por parte del equipo de desarrollo, restricciones legales y las preferencias del cliente. En cualquier caso, es muy común que se requiera el uso de diversas técnicas para la solución de un problema, particularmente si es un problema complejo.\n",
    "    * *Generación del plan de pruebas*. Una vez seleccionadas las técnicas de modelado, se debe crear un plan de cómo realizar la implementación del prototipo (lo que suele llamarse la \"**prueba de concepto**\"). Esta actividad incluye tareas como la selección de bibliotecas y herramientas, la implementación de las técnicas, definición de una estrategia de segmentación de datos para creación del modelo y para realización de pruebas y selección de medidas de evaluación.\n",
    "    * *Construcción del modelo*. A continuación, se construye el modelo (o conjunto de modelos, colaborativos o competidores). Se definen los parámetros de cada modelo, se hacen pruebas preliminares y se realizan ajustes al modelo. Aquí es importante destacar el carácter incierto típico en todo proyecto de minería de datos que obliga, frecuentemente a regresar a pasos previos, en este caso a la selección de modelos, definición de parámetros e incluso, a la fase de preparación de los datos. El resultado debe ser un modelo afinado, adecuado al problema.\n",
    "    * *Evaluación del modelo*. Finalmente, se evalúa el modelo, haciendo pruebas con los datos reservados para ello, se realiza un reporte de los niveles de precisión/error, tiempos de respuesta, potenciales puntos críticos y cualquier otra información que sea relevante para la implementación final del sistema.\n",
    "\n",
    "![](../images/crisp_dm_flow04.png)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Evaluación**<br>\n",
    "El resultado esperado de la fase de modelado es un modelo o un conjunto de modelos con un buen desempeño desde un punto de vista de los datos; es decir, un conjunto de modelos capaces de \"explicar\" el comportamiento de los datos. En la fase de evaluación se analiza la pertinencia de los modelos desarrollados en relación con los objetivos del negocio. <br><br>Las actividades por realizar en esta fase son:\n",
    "    * *Evaluación de los resultados*. En esta fase se evalúan los resultados que arrojan los modelos desarrollados y se comparan tales resultados con los objetivos de negocio. Se identifican objetivos del negocio que pudieran no estar resueltos y que pudieran requerir incluir nuevas herramientas e incluso, se analiza la posibilidad de ampliar los objetivos de negocio con resultados emergentes del modelado.\n",
    "    * *Revisión del proceso*. Aquí se realiza una revisión de todo el proceso seguido hasta el momento, desde la comprensión del negocio, se realizan los ajustes necesarios en cada etapa yt se presentan propuestas de como mejorar todo el proceso.\n",
    "    * *Determinación de los pasos siguientes*. En este paso se plantean las opciones a seguir, que pueden ir desde abandonar el proyecto (si los resultados obtenidos hasta el momento prevén un impacto no rentable en el negocio), regresar a la fase inicial, replantear y corregir los pasos necesarios o preceder a la implementación. \n",
    "\n",
    "![](../images/crisp_dm_flow05.png)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Despliegue**<br>\n",
    "Una vez realizado el modelado del problema y obtenidos resultados satisfactorios, es necesario transformar el modelo obtenido en un producto. Este producto puede ser un nuevo sistema de información para la toma de decisiones, una herramienta para detección de determinados comportamientos de interés en los datos que genera la empresa o una ampliación del conocimiento de la empresa que conduzca a nuevos procedimientos. <br><br>Esta fase contempla las siguientes actividades:\n",
    "    * *Planificación de la implementación*. Este paso es determinante para lograr que la implementación se integre adecuadamente y con la menor perturbación posible al sistema actual. Deben definirse como se extenderán los sistemas actuales para incorporar los nuevos resultados, como se modificarán los procedimientos de acuerdo a la nueva información de negocios, cómo se desarrollarán los recursos humanos necesarios para la implementación de los cambios. \n",
    "    * *Planificación del control y del mantenimiento*. Además de planificar la implementación, hay que planificar los procedimientos de control y mantenimiento que permitan darle seguimiento a los resultados que se espera obtener, particularmente en lo que se refiere a rentabilidad y estabilidad.\n",
    "    * *Generación de un informe final*. El paso final del proyecto es elaborar un reporte final, que incluya la documentación técnica del proyecto, manuales de usuario y casos de uso. Adicionalmente, deben generarse un reporte ejecutivo que resuma los resultados del proyecto y cualquier otro apoyo para la presentación final ante el cliente. \n",
    "    * *Revisión del proyecto*. Adicionalmente, en esta fase se elabora también un reporte anecdótico acerca del desarrollo del proyecto, que facilite el desarrollo de posteriores proyectos de innovación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/crisp_dm_flow06.png)<br><br>\n",
    "\n",
    "La metodología CRISP-DM permite mantener la atención puesta a todos los aspectos importantes para asegurar el éxito de un proyecto de minería de datos, por lo qué, de manera explícita o implícita, es conveniente tenerlo como guía.\n",
    "\n",
    "![](../images/crisp_dm_diagram_notes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "* El interés de la industria por las metodologías de aprendizaje automático (y reconocimiento de patrones, por lo tanto), se debe a la promesa de mejorar la productividad de las empresas. Este interés genera oportunidades de negocio, opciones de [empleo bien pagadas](https://www.indeed.com/q-Machine-Learning-jobs.html), vinculación industria-universidad, desarrollo regional. \n",
    "\n",
    "* Para poder aprovechar estas oportunidades, es importante establecer un plan de acción sistemático, basado en una buena comprensión de lo que el cliente busca.\n",
    "\n",
    "* CRISP-DM es la metodología *de facto* en la industria para el desarrollo de proyectos de minería de datos. Esta metodología hace énfasis en garantizar que las soluciones planteadas se integren adecuadamente al negocio y le generen valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agile, Desing Tinking y  Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El crecimiento del interés de la industria en las metodologías de ciencia de datos  ha venido acompañado de una formalización del proceso de desarrollo de soluciones. \n",
    "\n",
    "Existen dos enfoques para el diseño de soluciones basadas en datos:\n",
    "\n",
    "\n",
    "<img src=\"../images/tabla.png\" width=\"80%\">\n",
    "\n",
    "- Existen frecuentes críticas las metodologías tradicionales por sus limitaciones, particularmente en lo referente a la fase de toma de decisiones\n",
    "\n",
    "\n",
    "- Las metodologías tradicionales están fuertemente ubicados en los campos técnicos y rara vez son considerados los tomadores de decisiones y estrategas.\n",
    "\n",
    "- El enfoque agile no radica solo en las tecnologías de análisis de datos y la recopilación de datos, sino también en el diseño de soluciones centradas en el usuario con un alto potencial comercial. \n",
    "\n",
    "- Selección de la metodología depende de la madurez y el grado de adaptabilidad  de las empresa a un enfoque digital basado en datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 1. Entendimiento de la necesidad (Design Thinking)\n",
    "\n",
    "**Objetivo:** asegurar que el problema está correctamente definido y alineado al negocio.\n",
    "\n",
    "**Entregables:**\n",
    "\n",
    "* Documento de **antecedentes y motivación** (justificación del proyecto).\n",
    "* **Definición de alcance y criterios de éxito** (ej. aumentar conversión en 5%).\n",
    "* **Mapa de stakeholders y roles** (quién aprueba, quién consume, quién opera).\n",
    "* **Plan general del proyecto** con hitos iniciales.\n",
    "* **Glosario de negocio y procesos documentados**, incluyendo definiciones clave para asegurar consistencia en toda la organización.\n",
    "* **Análisis de riesgos del proyecto**, identificando riesgos técnicos, de negocio y regulatorios.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 2. Modelado (CRISP-DM)\n",
    "\n",
    "**Objetivo:** preparar datos, construir modelos candidatos y compararlos bajo criterios técnicos y de negocio.\n",
    "\n",
    "**Entregables:**\n",
    "\n",
    "1. **Perfilado de datos orientado a producción**\n",
    "\n",
    "   * Reportes de calidad y disponibilidad de datos (*pandas-profiling*, *Great Expectations*).\n",
    "   * Configuración de alertas de datos para detectar problemas críticos (sesgos, drift, valores faltantes, outliers).\n",
    "   * Priorización de temas críticos cuando el tiempo es limitado.\n",
    "   * Consideración de **ética y sesgos** en los datos y las decisiones del modelo.\n",
    "\n",
    "2. **EDA planificado y riguroso**\n",
    "\n",
    "   * Guiado por hallazgos del perfilado y alertas.\n",
    "   * Ajuste del nivel de detalle según número de features y tiempo disponible.\n",
    "   * **Selección de features**:\n",
    "\n",
    "     * Basada en importancia (top features por métricas de importancia de modelos o correlación).\n",
    "     * Exclusión de features no relacionadas directamente con el contexto de negocio.\n",
    "     * Descarte básico de features nulos, constantes o redundantes.\n",
    "     * Eliminación de features con **interpretabilidad compleja**, documentando justificación de negocio.\n",
    "\n",
    "       * Ejemplo: un feature que representa el porcentaje de batería del celular en un modelo antifraude se evalúa críticamente: si no hay lógica clara de negocio que lo respalde, se descarta para evitar decisiones confusas.\n",
    "   * **Ingeniería de features documentada**, incluyendo transformaciones, combinaciones y supuestos de negocio.\n",
    "\n",
    "3. **Construcción del baseline**\n",
    "\n",
    "   * Modelo inicial de referencia para medir mejoras.\n",
    "   * **Reporte de interpretabilidad** (SHAP, LIME, feature importance) para cada feature, con documentación de relevancia de negocio.\n",
    "\n",
    "4. **Optimización y experimentación con algoritmos candidatos**\n",
    "\n",
    "   * Entrenamiento de al menos dos algoritmos distintos.\n",
    "   * Búsqueda de hiperparámetros para configuración óptima.\n",
    "   * Selección preliminar del **golden model** según métricas técnicas (Lift, KS, Profit).\n",
    "   * **Documentación de experimentos**, métricas y decisiones para reproducibilidad y auditoría.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 3. Construcción objetiva (MLOps)\n",
    "\n",
    "**Objetivo:** trasladar el modelo a un sistema productivo.\n",
    "\n",
    "**Entregables:**\n",
    "\n",
    "* **Modelo entrenado y versionado** (con pipeline de features).\n",
    "* **Arquitectura de despliegue** documentada.\n",
    "* **Pruebas de integración** (datos, APIs, sistemas externos).\n",
    "* **Pipeline de CI/CD/CT** (automatización de entrenamiento y despliegue).\n",
    "* **Visualización / dashboard** de resultados para stakeholders.\n",
    "* **Definición de SLAs, fallback y plan de escalabilidad** según criticidad del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 4. Validación\n",
    "\n",
    "**Objetivo:** asegurar que la solución cumple los objetivos y es confiable.\n",
    "\n",
    "**Entregables:**\n",
    "\n",
    "* **Estrategia de Shadow ML** para pruebas paralelas sin afectar producción.\n",
    "* **Contrafactuales y análisis de umbrales**\n",
    "\n",
    "  * Simulaciones para balancear beneficios económicos vs. falsos positivos.\n",
    "  * Definición del **threshold óptimo** según escenarios de negocio.\n",
    "* **Evaluación de desempeño técnico** (precisión, recall, RMSE, etc.).\n",
    "* **Monitoreo en tiempo real** (alertas de degradación, métricas de drift).\n",
    "* **Reporte de impacto en negocio** (ahorros, ingresos, eficiencia).\n",
    "* **Gobernanza, seguridad y privacidad de los datos**.\n",
    "* **Estrategia de entrenamiento continuo** para mantener performance y adaptabilidad.\n",
    "* **Métricas de robustez y estabilidad** frente a cambios en los datos.\n",
    "* **Protocolo formal de revisión ética y de sesgos**, con checklist de cumplimiento y transparencia.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 5. Toma de decisiones y feedback\n",
    "\n",
    "**Objetivo:** mantener el ciclo de mejora continua.\n",
    "\n",
    "**Entregables:**\n",
    "\n",
    "* **Informe ejecutivo** con conclusiones y recomendaciones.\n",
    "* **Revisión de lecciones aprendidas** (qué funcionó y qué no).\n",
    "* **Roadmap de siguientes pasos** (nuevas features, nuevos casos de uso).\n",
    "* **Ciclo de aprendizaje continuo documentado**, registrando cambios de modelo, nuevas features y retroalimentación de negocio.\n",
    "\n",
    "---\n",
    "\n",
    "Una etapa adicional, que ya es obligatoria pero que generalmente aún no se considera una etapa formal, y que en la vida real es igual de importante y posiblemente igual de compleja, es la construcción del dataset:\n",
    "\n",
    "## 🔹 . Construcción del dataset\n",
    "\n",
    "**Objetivo:** estructurar el dataset base para el modelado, definiendo rango temporal, granularidad, target, features y particiones de forma alineada con la necesidad de negocio y el tipo de algoritmo a utilizar.\n",
    "\n",
    "**Entregables esperados:**\n",
    "\n",
    "1. **Definición del rango temporal y granularidad de los datos**\n",
    "\n",
    "   * Cobertura de un periodo representativo para el caso de uso (ej. 12 meses, cortes mensuales, ventanas diarias).\n",
    "   * Granularidad definida según la frecuencia operativa del modelo (día, semana, mes, evento).\n",
    "   * Documentar claramente fechas de inicio, fin y frecuencia.\n",
    "\n",
    "2. **Definición del target orientada al negocio**\n",
    "\n",
    "   * Si existen etiquetas confiables → se usan directamente.\n",
    "   * Si no existen → se construye un **criterio de negocio** que defina la clase positiva y negativa.\n",
    "   * Ejemplo general: en un modelo de fraude, clase positiva (1) = transacciones acumuladas > X monto en Y tiempo con señales sospechosas; clase negativa (0) = transacciones normales.\n",
    "   * La definición debe validarse con stakeholders y quedar documentada.\n",
    "\n",
    "3. **Construcción del dataset maestro**\n",
    "\n",
    "   * Integración de todas las fuentes en un dataset coherente.\n",
    "   * Limpieza de valores faltantes, normalización de formatos y tipos de dato.\n",
    "   * Validación inicial de consistencia y representatividad.\n",
    "\n",
    "4. **Definición y construcción de features**\n",
    "\n",
    "   * Selección de features relevantes del negocio y sistemas fuente.\n",
    "   * Generación de nuevas features derivadas (ratios, lags, rolling windows, cíclicas como día de la semana, hora del día, mes del año).\n",
    "   * Features de corto plazo vs. largo plazo, según el patrón esperado.\n",
    "   * Documentación de cada feature: origen, transformación, justificación.\n",
    "\n",
    "5. **Ordenamiento del dataset según algoritmo**\n",
    "\n",
    "   * Para modelos clásicos (árboles, regresiones): orden aleatorio, garantizando independencia.\n",
    "   * Para modelos secuenciales (RNN, Transformers, series de tiempo): orden histórico preservado, respetando la secuencia temporal de eventos.\n",
    "   * Para casos híbridos: mantener orden parcial y generar features de secuencia o eventos acumulados.\n",
    "\n",
    "6. **Estrategia de partición Train/Test/Validation**\n",
    "\n",
    "   * **Train:** se permite balanceo si es necesario.\n",
    "   * **Test:** mantener proporción real de clases (simula el ambiente productivo).\n",
    "   * **Validation:** partición temporal o k-fold, dependiendo de la naturaleza del problema.\n",
    "   * Revisar que no exista *data leakage*.\n",
    "\n",
    "7. **Calibración y verificación inicial del dataset**\n",
    "\n",
    "   * Revisión estadística de distribuciones en Train/Test/Validation.\n",
    "   * Confirmación de representación suficiente del target en cada split.\n",
    "   * Validación de que las features se comportan de manera estable en el tiempo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/metologia.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciclo de vida de un ML Model\n",
    "\n",
    "<img src=\"../images/ciclo_de_vida.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "###### <a name=\"tarea_2\">Tarea 2</a>\n",
    "\n",
    "Presente el análisis de un problema de reconocimiento de patrones utilizando la metodología CRISP-DM."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
